{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The aim of this notebook is to test the implementation by using TS to optimize the\n",
    "Alpine2 function.\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: TkAgg\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import Tensor\n",
    "from botorch.models import SingleTaskGP\n",
    "from botorch.test_functions import SyntheticTestFunction\n",
    "from botorch.acquisition import PosteriorMean\n",
    "from botorch.optim import optimize_acqf\n",
    "from gpytorch.mlls import ExactMarginalLogLikelihood\n",
    "from gpytorch.utils.errors import NotPSDError\n",
    "from botorch import fit_gpytorch_model\n",
    "from gp_sampling.decoupled_samplers import decoupled_sampler\n",
    "from gp_sampling.thompson_samplers import decoupled_ts, exact_ts\n",
    "from typing import Optional, Union\n",
    "import math\n",
    "from botorch.models.transforms import Standardize\n",
    "%matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "class Alpine2(SyntheticTestFunction):\n",
    "    \"\"\"\n",
    "    The Alpine-2 test function.\n",
    "\n",
    "    n-dimensional function typically evaluated on x_i in [0, 10].\n",
    "    This implementation is rescaled to [0, 1].\n",
    "\n",
    "    A(x) = - prod_{i=1}^n sqrt(x_i) sin(x_i).\n",
    "        (negated to make it into a minimization problem by default)\n",
    "    Scaled (w/ x_i in [0, 1]):\n",
    "    A(x) = - prod_{i=1}^n sqrt(10 * x_i) sin(10 * x_i)\n",
    "\n",
    "    The global optimum is found at x_i â‰ˆ 7.91705268466621...\n",
    "    Rescaled: 0.7917052...\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, dim=6, noise_std: Optional[float] = None, negate: bool = False\n",
    "    ) -> None:\n",
    "        self.dim = dim\n",
    "        self._bounds = [(0.0, 1.0) for _ in range(self.dim)]\n",
    "        self._optimizers = [tuple(0.791705268466621 for _ in range(self.dim))]\n",
    "        self._optimal_value = -math.pow(2.808130979537964, self.dim)\n",
    "        super().__init__(noise_std=noise_std, negate=negate)\n",
    "\n",
    "    def evaluate_true(self, X: Tensor) -> Tensor:\n",
    "        X = 10 * X\n",
    "        return -torch.prod(torch.sqrt(X) * torch.sin(X), dim=-1, keepdim=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def run_one_replication(\n",
    "    iterations: int,\n",
    "    dim: int,\n",
    "    num_draws: int = 2 ** 6,\n",
    "    q: int = 1,\n",
    "    num_basis: int = 2 ** 8,\n",
    "    decoupled: bool = True,\n",
    "    seed: Optional[int] = None,\n",
    "    device: Optional[Union[torch.device, str]] = None\n",
    ") -> Tensor:\n",
    "    r\"\"\"\n",
    "    Runs one replication of BO using TS to optimize Alpine2 function.\n",
    "\n",
    "    Args:\n",
    "        iterations: Number of iterations\n",
    "        dim: Dimension of the problem\n",
    "        num_draws: Number of samples to use for TS\n",
    "        q: Number of parallel evaluations\n",
    "        num_basis: Number of basis functions to use for decoupled sampler\n",
    "        decoupled: If True, uses decoupled sampler. Otherwise, samples from exact GP.\n",
    "        seed: The seed for random number generation\n",
    "        device: Option to specify cpu / gpu. If not decoupled, defaults to GPU if\n",
    "        available. For decoupled, defaults to CPU.\n",
    "\n",
    "    Returns:\n",
    "        An `iterations+1` tensor of output performance. Evaluated as the function value\n",
    "            at the maximizer of PosteriorMean.\n",
    "    \"\"\"\n",
    "    if device is None:\n",
    "        if decoupled:\n",
    "            device = torch.device(\"cpu\")\n",
    "        else:\n",
    "            device = (\n",
    "                torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "            )\n",
    "    else:\n",
    "        device = torch.device(device) if isinstance(device, str) else device\n",
    "    if seed is not None:\n",
    "        torch.manual_seed(seed)\n",
    "    function = Alpine2(dim=dim)\n",
    "    bounds = torch.tensor([[0.], [1.]], device=device).repeat(1, dim)\n",
    "    train_X = torch.rand(2*dim + 2, 2, device=device)\n",
    "    train_Y = function(train_X).reshape(-1, 1)\n",
    "\n",
    "    def current_best() -> Tensor:\n",
    "        r\"\"\"\n",
    "        Returns the current best solution value, evaluated as the true function value\n",
    "        at the maximizer of PosteriorMean\n",
    "\n",
    "        Returns:\n",
    "            A tensor with the current best value\n",
    "        \"\"\"\n",
    "        pm = PosteriorMean(model)\n",
    "        current_best_point, _ = optimize_acqf(\n",
    "            acq_function=pm,\n",
    "            bounds=bounds,\n",
    "            q=1,\n",
    "            num_restarts=10*dim,\n",
    "            raw_samples=200*dim\n",
    "        )\n",
    "        return function.evaluate_true(current_best_point).reshape(-1)\n",
    "\n",
    "    def update_gp() -> SingleTaskGP:\n",
    "        r\"\"\"\n",
    "        Updates (refits) the GP model using the most recent data\n",
    "\n",
    "        Returns:\n",
    "            The fitted GP model\n",
    "        \"\"\"\n",
    "        gp = SingleTaskGP(train_X, train_Y, outcome_transform=Standardize(m=1))\n",
    "        mll = ExactMarginalLogLikelihood(gp.likelihood, gp)\n",
    "        fit_gpytorch_model(mll)\n",
    "        return gp\n",
    "\n",
    "    output = torch.empty(iterations+1, device=device)\n",
    "    for i in range(iterations):\n",
    "        iter_start = time()\n",
    "        # fit the gp and get the current performance\n",
    "        model = update_gp()\n",
    "        output[i] = current_best()\n",
    "        if decoupled:\n",
    "            # draw the thompson sample using decoupled sampler\n",
    "            ps = decoupled_sampler(model=model, sample_shape=[q], num_basis=num_basis)\n",
    "            next_sample = decoupled_ts(ps, num_draws=num_draws, d=dim)\n",
    "        else:\n",
    "            # draw the thompson sample using exact posterior\n",
    "            next_sample = exact_ts(model, num_draws=num_draws, d=dim)\n",
    "        next_eval = function(next_sample).reshape(-1, 1)\n",
    "        train_X = torch.cat([train_X, next_sample])\n",
    "        train_Y = torch.cat([train_Y, next_eval])\n",
    "        print(\"iter %d with decoupled %s took %s\" % (i, decoupled, time()-iter_start))\n",
    "\n",
    "    # add the final performance after all observations\n",
    "    model = update_gp()\n",
    "    output[-1] = current_best()\n",
    "    return output"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Run a comparison of exact TS and decoupled TS on the 2d Alpine2 problem."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/saitcakmak/anaconda3/envs/gp-sampling/lib/python3.8/site-packages/torch/cuda/__init__.py:53: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at  /opt/conda/conda-bld/pytorch_1598944191421/work/c10/cuda/CUDAFunctions.cpp:100.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 0 with decoupled False took 0.2189338207244873\n",
      "iter 1 with decoupled False took 0.46135568618774414\n",
      "iter 2 with decoupled False took 0.19448161125183105\n",
      "iter 3 with decoupled False took 0.7627942562103271\n",
      "iter 4 with decoupled False took 0.9630508422851562\n",
      "iter 5 with decoupled False took 0.8840408325195312\n",
      "iter 6 with decoupled False took 0.4963827133178711\n",
      "iter 7 with decoupled False took 1.7268507480621338\n",
      "iter 8 with decoupled False took 1.980445384979248\n",
      "iter 9 with decoupled False took 1.084465742111206\n",
      "iter 10 with decoupled False took 1.3961007595062256\n",
      "iter 11 with decoupled False took 1.497725248336792\n",
      "iter 12 with decoupled False took 2.851093292236328\n",
      "iter 13 with decoupled False took 4.799160957336426\n",
      "iter 14 with decoupled False took 2.331326723098755\n",
      "iter 15 with decoupled False took 2.8272359371185303\n",
      "iter 16 with decoupled False took 4.882258176803589\n",
      "iter 17 with decoupled False took 7.02118182182312\n",
      "iter 18 with decoupled False took 4.3998939990997314\n",
      "iter 19 with decoupled False took 4.065138816833496\n",
      "iter 20 with decoupled False took 4.016759157180786\n",
      "iter 21 with decoupled False took 9.5923011302948\n",
      "iter 22 with decoupled False took 4.700658798217773\n",
      "iter 23 with decoupled False took 11.875230550765991\n",
      "iter 24 with decoupled False took 8.389526128768921\n",
      "iter 25 with decoupled False took 16.901808500289917\n",
      "iter 26 with decoupled False took 21.31529688835144\n",
      "iter 27 with decoupled False took 21.538905143737793\n",
      "iter 28 with decoupled False took 16.84214186668396\n",
      "iter 29 with decoupled False took 34.52479529380798\n",
      "iter 30 with decoupled False took 38.396159410476685\n",
      "iter 31 with decoupled False took 21.53702974319458\n",
      "iter 32 with decoupled False took 26.722739934921265\n",
      "iter 33 with decoupled False took 19.023094415664673\n",
      "iter 34 with decoupled False took 65.71032190322876\n",
      "iter 35 with decoupled False took 40.47779583930969\n",
      "iter 36 with decoupled False took 28.580756187438965\n",
      "iter 37 with decoupled False took 42.67262411117554\n",
      "iter 38 with decoupled False took 33.64529252052307\n",
      "iter 39 with decoupled False took 47.01064324378967\n",
      "iter 40 with decoupled False took 33.55131411552429\n",
      "iter 41 with decoupled False took 38.11123752593994\n",
      "iter 42 with decoupled False took 36.63973641395569\n",
      "iter 43 with decoupled False took 46.52505970001221\n",
      "iter 44 with decoupled False took 55.91011714935303\n",
      "iter 45 with decoupled False took 99.46794176101685\n",
      "iter 46 with decoupled False took 124.38564229011536\n",
      "iter 47 with decoupled False took 63.767789125442505\n",
      "iter 48 with decoupled False took 117.75804853439331\n",
      "iter 49 with decoupled False took 80.90466713905334\n",
      "iter 0 with decoupled False took 0.3143448829650879\n",
      "iter 1 with decoupled False took 0.6651515960693359\n",
      "iter 2 with decoupled False took 0.33787059783935547\n",
      "iter 3 with decoupled False took 0.5850121974945068\n",
      "iter 4 with decoupled False took 0.36945271492004395\n",
      "iter 5 with decoupled False took 0.7333383560180664\n",
      "iter 6 with decoupled False took 0.850292444229126\n",
      "iter 7 with decoupled False took 0.652503252029419\n",
      "iter 8 with decoupled False took 0.9812040328979492\n",
      "iter 9 with decoupled False took 1.0692708492279053\n",
      "iter 10 with decoupled False took 1.9635043144226074\n",
      "iter 11 with decoupled False took 1.7673704624176025\n",
      "iter 12 with decoupled False took 2.062824249267578\n",
      "iter 13 with decoupled False took 3.4113245010375977\n",
      "iter 14 with decoupled False took 4.951839923858643\n",
      "iter 15 with decoupled False took 2.0928192138671875\n",
      "iter 16 with decoupled False took 7.323930740356445\n",
      "iter 17 with decoupled False took 13.44685673713684\n",
      "iter 18 with decoupled False took 2.8908615112304688\n",
      "iter 19 with decoupled False took 4.316972017288208\n",
      "iter 20 with decoupled False took 10.501561164855957\n",
      "iter 21 with decoupled False took 3.7899227142333984\n",
      "iter 22 with decoupled False took 6.219348669052124\n",
      "iter 23 with decoupled False took 5.994704484939575\n",
      "iter 24 with decoupled False took 5.41428804397583\n",
      "iter 25 with decoupled False took 26.981696605682373\n",
      "iter 26 with decoupled False took 11.188327312469482\n",
      "iter 27 with decoupled False took 8.421828508377075\n",
      "iter 28 with decoupled False took 14.103217601776123\n",
      "iter 29 with decoupled False took 7.598137378692627\n",
      "iter 30 with decoupled False took 10.099843740463257\n",
      "iter 31 with decoupled False took 19.031854391098022\n",
      "iter 32 with decoupled False took 43.49115252494812\n",
      "iter 33 with decoupled False took 18.76851201057434\n",
      "iter 34 with decoupled False took 17.056626081466675\n",
      "iter 35 with decoupled False took 18.401464223861694\n",
      "iter 36 with decoupled False took 20.796191692352295\n",
      "iter 37 with decoupled False took 28.305023908615112\n",
      "iter 38 with decoupled False took 33.34641122817993\n",
      "iter 39 with decoupled False took 33.54535961151123\n",
      "iter 40 with decoupled False took 32.74382019042969\n",
      "iter 41 with decoupled False took 52.242801666259766\n",
      "iter 42 with decoupled False took 33.03617978096008\n",
      "iter 43 with decoupled False took 52.662654399871826\n",
      "iter 44 with decoupled False took 30.989798069000244\n",
      "iter 45 with decoupled False took 45.48441934585571\n",
      "iter 46 with decoupled False took 34.75893449783325\n",
      "iter 47 with decoupled False took 74.47185802459717\n",
      "iter 48 with decoupled False took 38.73922681808472\n",
      "iter 49 with decoupled False took 39.91038656234741\n"
     ]
    }
   ],
   "source": [
    "replications = 2\n",
    "iterations = 50\n",
    "dim = 2\n",
    "decoupled_out = torch.zeros(replications, iterations+1)\n",
    "exact_out = torch.zeros(replications, iterations+1)\n",
    "run_decoupled = True\n",
    "run_exact = True\n",
    "executed = torch.ones(replications, dtype=torch.long)\n",
    "for i in range(replications):\n",
    "    try:\n",
    "        if run_decoupled:\n",
    "            decoupled_out[i] = run_one_replication(\n",
    "                iterations, dim, decoupled=True, seed=i\n",
    "            )\n",
    "        if run_exact:\n",
    "            exact_out[i] = run_one_replication(iterations, dim, decoupled=False, seed=i)\n",
    "    except NotPSDError:\n",
    "        executed[i] = 0\n",
    "\n",
    "executed = executed.to(dtype=torch.bool)\n",
    "plt.plot(torch.mean(decoupled_out[executed], dim=0), label=\"decoupled TS\")\n",
    "plt.plot(torch.mean(exact_out[executed], dim=0), label=\"exact TS\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([True, True])"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "executed"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}